# Debate: Yoshua Bengio & Gary Marcus on the best way forward for AI 
*2019 December 23, Monday at 6:30PM EST | Moderated by Vincent Boucher | #AIDebate*

Home Page: [Montreal AI](https://montrealartificialintelligence.com/aidebate/), Registration: [EventBrite](https://www.eventbrite.ca/e/debate-yoshua-bengio-gary-marcus-live-streaming-tickets-81620778947)

  Recording: [Montrea.AI Livestream Video on YouTube](https://www.youtube.com/watch?v=EeqwFjqFvJA)
  
  Presentation Slides: [Marcus](https://montrealartificialintelligence.com/aidebate/slidesmarcus.pdf), [Bengio](https://montrealartificialintelligence.com/aidebate/slidesbengio.pdf)


## Post-Debate Materials
### Ongoing Discussion
1. Marcus:  [Bengio-Marcus AI Debate Post Mortem, Part I: The Deep Learning Pivot](https://medium.com/@GaryMarcus/bengio-marcus-ai-debate-post-mortem-part-i-the-deep-learning-pivot-f7bd62b9861c?)
1. Bengio: ["Response to Gary Marcus - December 26th 2019"](https://docs.google.com/document/d/1P9YyZ4xEDO98qPTa1Al4RnTqxj3mMiCvQE4i3hZkthY/edit?usp=sharin)
1. Marcus: [A research program is not a set of techniques: A brief response to Yoshua Bengio’s December 26 reply to me
](https://medium.com/@GaryMarcus/a-research-program-is-not-a-set-of-techniques-a-brief-response-to-yoshua-bengios-december-26-fafc0a29ffc9)
1. Marcus: [Deep learning, science, engineering, research, and terminology](https://medium.com/@GaryMarcus/deep-learning-science-engineering-research-and-terminology-292a747a94d3)

### Outside Commentary
* Recap by [Tiernan Ray](https://www.zdnet.com/article/devils-in-the-details-in-bengio-marcus-ai-debate/) "Devil’s in the details in Historic AI debate: An historic debate between two of the artificial intelligence illuminati was mostly simpatico on the big questions -- creating hybrid systems of AI, finding the right "priors" for knowledge -- but it was also punctuated by sharp differences on some of the details."
* Additional YouTube housing by Lex Fridman, with some interesting/different comments below the video: https://www.youtube.com/watch?v=pKgseaENkAU 


## Pre-Debate Materials
### "The First Debate"
Some have mentioned this webinar debate will be a "sequal" - here is a [more personal recount (per Marcus) of what has transpired](https://medium.com/@GaryMarcus/the-current-state-of-ai-and-deep-learning-a-reply-to-yoshua-bengio-77952ead7970)

### Papers & Textbooks
##### Marcus
* Rebooting AI (Chapters 4 and 7), Gary Marcus and Ernest Davis, 2019
* The Algebraic Mind (Chapters 3 - 5), Gary Marcus, 2001
* The Birth of the Mind (Chapters 6 - 8), Gary Marcus, 2004
* Deep Learning: A Critical Appraisal, Gary Marcus, 2018:https://arxiv.org/abs/1801.00631.vInnateness, 
* AlphaZero, and Artificial Intelligence, Gary Marcus, 2018:https://arxiv.org/abs/1801.05667.vRethinking  
* Eliminative  Connectionism, Gary Marcus, 1998:https://www.sciencedirect.com/science/article/pii/S0010028598906946
* ^ Suggested Pre-Readings
* Equilibrium Propagation: Bridging the Gap between Energy-Based Models and Backpropagation https://www.frontiersin.org/articles/10.3389/fncom.2017.00024/full
* Deep Learning: A Critical Appraisal - Gary Marcus https://arxiv.org/abs/1801.00631?

##### Bengio
* BabyAI: First Steps Towards Grounded Language Learning With a Human In the Loop, Chevalier-Boisvert et al.,2018: https://arxiv.org/abs/1810.08272v2.vA  
* First Steps Towards Grounded Language Learning With a Human In the Loop, Chevalier-Boisvert et al.,2018: https://arxiv.org/abs/1810.08272v2.vA
* Meta-Transfer Objective for Learning to Disentangle Causal Mechanisms, Bengio et al., 2019: https://arxiv.org/abs/1901.10912.vLearning 
* Neural Causal Models from Unknown Interventions, Ke et al., 2019: https://arxiv.org/abs/1910.01075.vRecurrent 
* Independent Mechanisms, Goyal et al., 2019: https://arxiv.org/abs/1909.10893.vThe 
* ^ Suggested Pre-Readings
* Consciousness Prior, Bengio et al., 2017: https://arxiv.org/abs/1709.08568.2
- How transferable are features in deep neural networks? Jason Yosinski, Jeff Clune, Yoshua Bengio, Hod Lipson https://arxiv.org/abs/1411.1792

### Related Content
- Lex Fridman [AGI Podcast (Transcript) with Marcus Gary](https://medium.com/@julian.harris/the-future-of-ai-gary-marcus-talks-with-lex-fridman-9ecd497abbe6)
- Pre-Debate Discussion: "Today, before the #AIDebate, I'll have a Pre-Debate Show on my @Twitch channel (https://twitch.tv/rhyolight_) featuring  @GaryMarcus's last debate with @ylecun."
- Yann LeCunn on [Facebook: What is Deep Learning](https://www.facebook.com/722677142/posts/10156463919392143/) "Some folks still seem confused about what deep learning is. Here is a definition: DL is constructing networks of parameterized functional modules & training them from examples using gradient-based optimization. That's it. This definition is orthogonal to the learning paradigm: reinforcement, supervised, or self-supervised." (excerpt) 
  - A related comment: "The essence of "deep" (and the original motivation for it), is the ability to learn hierarchical representations. If a methodology allows it, and uses gradient-based optimization, then it qualifies as deep learning. But one can always use the DL methodology for building and training non-deep architectures. Perhaps my definition should include "networks of differentiable modules, with no restriction that they be shallow or that only the last stage be trainable." But that's kind of implied."


